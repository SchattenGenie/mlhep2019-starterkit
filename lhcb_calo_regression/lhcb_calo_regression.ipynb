{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h5py import File as HDF5File\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "sns.set()\n",
    "\n",
    "def one_hot(a, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[a.reshape(-1)])\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "Data is stored in `.npz`-format which is a special file type for persisting multiple NumPy arrays on disk(ore info: https://docs.scipy.org/doc/numpy/reference/generated/numpy.lib.format.html#module-numpy.lib.format).\n",
    "\n",
    "File contains three arrays: \n",
    "\n",
    "  * `EnergyDeposit` - images of calorimeters responses\n",
    "  * `ParticleMomentum` - $p_x, p_y, p_z$ of initial partice\n",
    "  * `ParticlePoint` - $x, y$ of initial particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_real = np.load('../real_quan.npz', allow_pickle=True)\n",
    "EnergyDeposit = data_real['EnergyDeposit']\n",
    "EnergyDeposit = EnergyDeposit.reshape(-1, 1, 30, 30)\n",
    "ParticleMomentum = data_real['ParticleMomentum']\n",
    "ParticlePoint = data_real['ParticlePoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('$p_x$-$p_y$ distribution')\n",
    "plt.scatter(ParticleMomentum[:, 0], ParticleMomentum[:, 1]);\n",
    "plt.xlabel('$p_x$')\n",
    "plt.ylabel('$y_x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.title('$x$-$y$ distribution')\n",
    "plt.scatter(ParticlePoint[:, 0], ParticlePoint[:, 1]);\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$x$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParticleMomentum = ParticleMomentum[:, :2]\n",
    "ParticlePoint = ParticlePoint[:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load it to pytorch `DataLoader` for faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EnergyDeposit = torch.tensor(EnergyDeposit).float()\n",
    "ParticleMomentum = torch.tensor(ParticleMomentum).float()\n",
    "ParticlePoint = torch.tensor(ParticlePoint).float()\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "calo_dataset = utils.TensorDataset(EnergyDeposit, ParticleMomentum, ParticlePoint)\n",
    "calo_dataloader = torch.utils.data.DataLoader(calo_dataset, \n",
    "                                              batch_size=BATCH_SIZE, \n",
    "                                              pin_memory=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining our neural network regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "class Regressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Regressor, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 2)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1600, 512) \n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 2 + 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x)) # 64, 5, 5\n",
    "        x = x.view(len(x), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Regressor().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "opt = optim.Adam(regressor.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative MSE that is used in competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParticleMomentum_mean, ParticlePoint_mean = ParticleMomentum.mean(dim=0), ParticlePoint.mean(dim=0)\n",
    "ParticleMomentum_ParticlePoint_mean = torch.cat([ParticleMomentum_mean, ParticlePoint_mean]).to(device)\n",
    "def metric_relative_mse(y_true, y_pred):\n",
    "    return ((y_true - y_pred).pow(2).mean(dim=0) / (y_true - ParticleMomentum_ParticlePoint_mean).pow(2).mean(dim=0)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningAverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, momentum=0.99):\n",
    "        self.momentum = momentum\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = None\n",
    "        self.avg = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        if self.val is None:\n",
    "            self.avg = val\n",
    "        else:\n",
    "            self.avg = self.avg * self.momentum + val * (1 - self.momentum)\n",
    "        self.val = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(epochs=100):\n",
    "    losses = []\n",
    "    metrics = []\n",
    "    loss_meter = RunningAverageMeter(momentum=0.99)\n",
    "    metric_meter = RunningAverageMeter(momentum=0.99)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b in calo_dataloader:\n",
    "            EnergyDeposit_b, ParticleMomentum_b, ParticlePoint_b = EnergyDeposit_b.to(device), \\\n",
    "                                                                   ParticleMomentum_b.to(device), \\\n",
    "                                                                   ParticlePoint_b.to(device)\n",
    "            pred = regressor(EnergyDeposit_b)\n",
    "\n",
    "            loss = loss_fn(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1))\n",
    "            losses.append(loss)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            loss_meter.update(loss.item())\n",
    "            metric_meter.update(metric_relative_mse(pred, torch.cat([ParticleMomentum_b, ParticlePoint_b], dim=1)).item())\n",
    "            losses.append(loss_meter.avg)\n",
    "            metrics.append(metric_meter.avg)\n",
    "\n",
    "                \n",
    "        clear_output()\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.plot(losses, label='Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.plot(metrics, label='Metric')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_training(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_val = np.load('./data_val.npz', allow_pickle=True)\n",
    "EnergyDeposit_val = data_val['EnergyDeposit']\n",
    "EnergyDeposit_val = EnergyDeposit_val.reshape(-1, 1, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_val = regressor.cpu()(torch.tensor(EnergyDeposit_val).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParticleMomentum_val, ParticlePoint_val = prediction_val.detach().numpy()[:, :2], prediction_val.detach().numpy()[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('data_val_prediction.npz', \n",
    "                    ParticlePoint=ParticlePoint_val, \n",
    "                    ParticleMomentum=ParticleMomentum_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = np.load('./data_test.npz', allow_pickle=True)\n",
    "EnergyDeposit_test = data_test['EnergyDeposit']\n",
    "EnergyDeposit_test = EnergyDeposit_test.reshape(-1, 1, 30, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = regressor.cpu()(torch.tensor(EnergyDeposit_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ParticleMomentum_test, ParticlePoint_test = predictio_test.detach().numpy()[:, :2], predictio_test.detach().numpy()[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('data_test_prediction.npz', \n",
    "                    ParticlePoint=ParticlePoint_test, \n",
    "                    ParticleMomentum=ParticleMomentum_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `zip` files together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip solution.zip data_val_prediction.npz ata_test_prediction.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('./solution.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
